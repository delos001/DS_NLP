{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters 'Crude' Article Analysis\n",
    "\n",
    "- Based on code and procedure from the Stanford NLP Deep Learning\n",
    "    - found in DS_Recipes/NLP/Stanford Class\n",
    "    - this file will exclude the instruction and sample code found in the tutorial and only focus on the analysis of the Reuters data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors\n",
    "\n",
    "- Word vectors and word embeddings are used interchangeably\n",
    "    - specify a word's meaning by changing from high one-dimensional space to a continuous vector that is a much lower dimension\n",
    "        - This is like taking the word 'run' and encoding as a vector of continuous numbers such as:\n",
    "            [1.002, -2.033, -9.881, 13.032, ..., 2.818] \n",
    "            \n",
    "- Word vectors center around idea that similar words have similar context, and thus will be relatively proximal to a shared subset of words\n",
    "\n",
    "## In this script:\n",
    "- Two main types of word vectors / word embeddings used in this script:\n",
    "    - Count-based word vectors: co-occurrence matrix\n",
    "    - Prediction-based word vectors: word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Global Variables\n",
    "- this may not be all inclusive as more may be more approriately run at beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 5\n",
    "\n",
    "import pprint\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "import nltk\n",
    "## download preloaded dataset (10,788 documents, 1.3 mil words)\n",
    "## https://www.nltk.org/book/ch02.html\n",
    "## uncomment download line below if not already downloaded\n",
    "# nltk.download('reuters') \n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "\n",
    "## Used for dimension reduction on co-occurrence matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## Generate global variablesabs\n",
    "## Start and End tokens will be applied to beginning\n",
    "##   and end of each document\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Corpus\n",
    "- Reuters corpus contain 90 categories that are split into train and test\n",
    "- for this project, the Reuters corpus will be subset to only include the \"Crude\" category which includes articles about oil, gas, etc\n",
    "- https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters:\n",
    "    category is a string referring to the Reuters category type\n",
    "Return: \n",
    "    a list of lists: a list of the words from each file\n",
    "'''\n",
    "\n",
    "\n",
    "def read_corpus(category='crude'):\n",
    "    files = reuters.fileids(category)\n",
    "    return[[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review article in the Reuters corpus selected for crude category\n",
    "\n",
    "# Remove and run to test-----------\n",
    "#my_corpus = read_corpus()\n",
    "#pprint.pprint(my_corpus[:1], compact=True, width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Distinct Words\n",
    "- try to avoid for loops since they are slower\n",
    "- instead use set comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters:\n",
    "    corpus: list of list from read file defined above\n",
    "Return:\n",
    "    corpus_words: list of string, distinct words across corpus, sorted\n",
    "    num_corpus_words: number of distinct words across corpus\n",
    "'''\n",
    "\n",
    "def distinct_words(corpus):\n",
    "    corpus_words_dist = sorted(list(set([word for doc in corpus for word in doc])))\n",
    "    corpus_words_dist_cnt = len(corpus_words_dist)\n",
    "    return corpus_words_dist, corpus_words_dist_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run distinct_words function\n",
    "#    print last 50 unique words and the number of unique words in corpus\n",
    "\n",
    "# Remove and run to test-----------\n",
    "#corpus_words_dist, corpus_words_dist_cnt = distinct_words(my_corpus)\n",
    "#print(corpus_words_dist[-50:])\n",
    "#print(corpus_words_dist_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Analysis Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count-Based Word Vector: Co-occurrence matrix\n",
    "\n",
    "- count of how often words co-occur with each other in a document based on a specified window\n",
    "    - a window of size $n$ means $n$ preceeding words and $n$ subsequent words in the document where $w_i$ is the word of interest\n",
    "        - $w_{i-n} \\dots w_{i-1}$, $w_i$, $w_{i+1} \\dots w_{i+n}$\n",
    "        \n",
    "        - iterating over the document in word by word fashion, each word becomes $w_i$ and the number of times $w_i$ occurs with other words in the window $n$ are counted and entered in a symetric matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
    "\n",
    "    Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
    "          number of co-occurring words.\n",
    "\n",
    "          For example, if we take the document \"START All that glitters is not gold END\" with window size of 4,\n",
    "          \"All\" will co-occur with \"START\", \"that\", \"glitters\", \"is\", and \"not\".\n",
    "\n",
    "    Params:\n",
    "        corpus (list of list of strings): corpus of documents\n",
    "        window_size (int): size of context window\n",
    "    Return:\n",
    "        M (numpy matrix of shape (number of corpus words, number of corpus words)): \n",
    "            Co-occurence matrix of word counts. \n",
    "            The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
    "        word2Idx (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
    "\"\"\"\n",
    "\n",
    "def compute_co_occurrence_matrix(corpus, window_size):\n",
    "\n",
    "    \n",
    "    # call the distinct words function to use unique words\n",
    "    corpus_words_dist, corpus_words_dist_cnt = distinct_words(corpus)\n",
    "    \n",
    "    M = None       # set to none at start of function\n",
    "    word2Idx = {}  # set to blank at start of function\n",
    "\n",
    "    # Create a matrix based on size of corpus after runing distinct_words function\n",
    "    M = np.zeros((corpus_words_dist_cnt, corpus_words_dist_cnt))  # create n by n matrix\n",
    "    \n",
    "    # Creates an word:index dictionary of entire unique word corpus\n",
    "    word2Idx = dict(zip(corpus_words_dist, range(corpus_words_dist_cnt)))\n",
    "\n",
    "    # Loop through each document (list of words) in corpus\n",
    "    for doc in corpus:\n",
    "        \n",
    "        # cur_idx will be the index number of each word within that document\n",
    "        # -used to sysematically go through each word (0 to len(doc)) and find words\n",
    "        # -that are window_size positions before and after that word\n",
    "        cur_idx = 0         # resets at 0 at start of each document\n",
    "        doc_len = len(doc)  # word count of each document\n",
    "        \n",
    "        ## while index is between zero and document length\n",
    "        while cur_idx < doc_len:\n",
    "            # far left and far right index numbers (based on cur_idx & window_size)\n",
    "            l_bound = max(cur_idx - window_size, 0)   # max excludes negative indices\n",
    "            r_bound = min(cur_idx + window_size + 1, doc_len)   # min stops at doc_len\n",
    "            \n",
    "            # all words for this iterations window index numbers (l_bound to r_bound)\n",
    "            window_words = doc[l_bound:cur_idx] + doc[(cur_idx + 1):r_bound]\n",
    "            \n",
    "            # get the word associated with the cur_idx\n",
    "            center_word = doc[cur_idx]\n",
    "            \n",
    "            # using that center_word, get it's index number within the entire corpus\n",
    "            #center_idx = word2Idx[center_word]\n",
    "\n",
    "            # Now that we have all the words in a specific window, count the number\n",
    "            # of times each word in the word window appears near the center word in\n",
    "            # the full corpus (within the window size)\n",
    "            for window_word in window_words:\n",
    "                # get full corpus dict index for the window word\n",
    "                window_idx = word2Idx[window_word]\n",
    "                # add 1 in matrix M for each window match\n",
    "                M[window_idx, word2Idx[center_word]] += 1\n",
    "                \n",
    "            cur_idx += 1\n",
    "            \n",
    "    return M, word2Idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Matrix Dimensionality\n",
    "\n",
    "- The resulting matrix from compute_co_occurrence_matrix is a large sparse matrix of shape:\n",
    "    - distinct words rows x distinct words columns\n",
    "- Singular Value Decomposition (SVD) is a generalized PCA to select top k principal components thus reducing the dimensionality and improving processing time while keeping semantic relationships between words\n",
    "    - SVD is computationally expensive so trucated SVD can provide k vector components if k is expected to be small\n",
    "        - https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "        - All of numpy, scipy, and scikit-learn (sklearn) provide some implementation of SVD, but\n",
    "        - Only scipy and sklearn provide an implementation of Truncated SVD, and \n",
    "        - Only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)\n",
    "    to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:\n",
    "        - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "\n",
    "    Params:\n",
    "        M (numpy matrix of shape (number of corpus words, number of corpus words)): co-occurence matrix of word counts\n",
    "        k (int): embedding size of each word after dimension reduction\n",
    "    Return:\n",
    "        M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.\n",
    "                In terms of the SVD from math class, this actually returns U * S\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def reduce_to_k_dim(M, k):\n",
    "\n",
    "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
    "    seed = 42  # set seed\n",
    "    # create new blank M_reduced (reset each time function is run)\n",
    "    M_reduced = None\n",
    "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
    "\n",
    "    tsvd = TruncatedSVD(n_components=k,\n",
    "                        n_iter=n_iters,\n",
    "                        random_state=seed)\n",
    "    M_reduced = tsvd.fit_transform(M)\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return M_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot M_reduced Word Embeddings\n",
    "\n",
    "- 2D vectors plotted using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
    "        NOTE: do not plot all the words listed in M_reduced / word2Idx.\n",
    "        Include a label next to each point.\n",
    "        \n",
    "        Params:\n",
    "            M_reduced (numpy matrix of shape (number of unique words in the corpus , k)): matrix of k-dimensioal word embeddings\n",
    "            word2Idx (dict): dictionary that maps word to indices for matrix M\n",
    "            words (list of strings): words whose embeddings we want to visualize\n",
    "\"\"\"\n",
    "\n",
    "def plot_embeddings(M_reduced, word2Idx, words):\n",
    "    x_coords = M_reduced[:, 0]\n",
    "    y_coords = M_reduced[:, 1]\n",
    "    \n",
    "    for word in words:\n",
    "        idx = word2Idx[word]\n",
    "        M_reduced_word = M_reduced[idx]\n",
    "        x = M_reduced_word[0]\n",
    "        y = M_reduced_word[1]\n",
    "        \n",
    "        plt.scatter(x, y, marker='x', color='red')\n",
    "        plt.text(x, y, word, fontsize=8)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Functions with Co-occurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 8185 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "reuters_corpus = read_corpus()\n",
    "my_corpus = reuters_corpus\n",
    "\n",
    "M_co_occurrence, word2Idx_co_occrrence = compute_co_occurrence_matrix(my_corpus, window_size = 4)\n",
    "M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k = 2)\n",
    "\n",
    "# Rescale rows to make them each of unit-length\n",
    "M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis = 1)\n",
    "M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # uses numpy array broadcasting\n",
    "\n",
    "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry',\n",
    "         'kuwait', 'oil', 'output', 'petroleum', 'venezuela']\n",
    "plot_embeddings(M_normalized, word2Idx_co_occrrence, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the output above: some clusters seem to align while others are where we would expect them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction-based word vectors: word2vec\n",
    "- using Word2Vec skip-gram model\n",
    "    - develop vector representation of a center word such that it predicts nearby words\n",
    "    - see paper: https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec():\n",
    "    \n",
    "    import gensim.downloader as api\n",
    "    \n",
    "    wv_from_bin = api.load('word2vec-google-news-300')\n",
    "    vocab = list(wv_from_bin.vocab.keys())\n",
    "    \n",
    "    print('Loaded vocab size %i' % len(vocab))\n",
    "    return wv_from_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "Loaded vocab size 3000000\n"
     ]
    }
   ],
   "source": [
    "# Note: setting variable wv_from_bin retains attributes such as\n",
    "    # .vocab.keys, .word_vec, .most_similar, .distance, etc\n",
    "\n",
    "wv_from_bin = load_word2vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Word2Vec Dimensionality\n",
    "\n",
    "- Compare word2vec embeddings to co-occurrence embeddings\n",
    "    - create matrix M with 3 mil word2vec vectors\n",
    "    - reduce_to_k_dim (truncated SVD function created above):\n",
    "        - reduce from 300-dimensional to 2-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Put word2vec vectors into matrix M\n",
    "\n",
    "Param:\n",
    "    wv_from_bin: vector object with keys (3mil word2vec vectors loaded from file)\n",
    "\n",
    "Return:\n",
    "    M: numpy matrix of shape (num words, 300) containing the vectors\n",
    "    word2Idx: dictionary mapping each word to its row in M\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_matrix_of_vectors(wv_from_bin,\n",
    "                          # try adding additional words if you want\n",
    "                          required_words=['barrels', 'bpd', 'ecuador',\n",
    "                                          'energy', 'industry', 'kuwait',\n",
    "                                          'oil', 'output', 'petroleum',\n",
    "                                          'venezuela']):\n",
    "\n",
    "    import random\n",
    "\n",
    "    words = list(wv_from_bin.vocab.keys())\n",
    "\n",
    "    print('Shuffling words...')\n",
    "    random.shuffle(words)\n",
    "    words = words[:10000]\n",
    "\n",
    "    print('Putting %i words into word2Idx and matrix M...' % len(words))\n",
    "    word2Idx = {}\n",
    "    M = []\n",
    "    curIdx = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            M.append(wv_from_bin.word_vec(word))\n",
    "            word2Idx[word] = curIdx\n",
    "            curIdx += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "        for word in required_words:\n",
    "            try:\n",
    "                M.append(wv_from_bin.word_vec(word))\n",
    "                word2Idx[word] = curIdx\n",
    "                curIdx += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "        M = np.stack(M)\n",
    "        print('Done')\n",
    "\n",
    "        return M, word2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling words...\n",
      "Putting 10000 words into word2Idx and matrix M...\n",
      "Done\n",
      "Running Truncated SVD over 11 words...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Run function to reduce from 300-dim word embeddings to k dimensionsabs\n",
    "M, word2Idx = get_matrix_of_vectors(wv_from_bin)\n",
    "M_reduced = reduce_to_k_dim(M, k = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Word2Vec Analysis\n",
    "\n",
    "- compare this output to that of the co-occurrence matrix plotted earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAEvCAYAAAByngQ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfXRV1b2v8ecHxJfrW9oCR0QQrZReFUHJRSmoCOqFSvEFr4qvWJAerZVyHadHLceTOnTYenpMU3wrVQ8qiFo9tuhREdTg+0tQEBU9Fx1BUQQUsLUVJGTeP3aIIQTBZq+E7DyfMTKy11pzrzln1mbvL3PNvVaklJAkSVI22rV0AyRJkgqZYUuSJClDhi1JkqQMGbYkSZIyZNiSJEnKkGFLkiQpQx1augFb0rFjx9SjR4+WboYkSdJWzZs37+OUUqfGtm23YatHjx5UVla2dDMkSZK2KiKWbGmbpxElSZIyZNiSJEnKUJPDVkR0i4gnI2JRRLwRERMaKRMR8duIWBwRr0XEoU2tV5IkqTXIx5ytauCSlNIrEbEbMC8iZqeU3qxXZjjQs/bnMOCm2t+SJEkFrckjWymlZSmlV2of/wVYBHRtUOwE4I6U8wJQHBFdmlq3JEnS9i6vc7YiogdwCPBig01dgffrLS9l80AmSZJUcPIWtiJiV+B+4KcppT833NzIU1Ij+xgfEZURUbly5cp8NU1SgVuzZg3/+Z//uc3lx4wZw+LFizNskSR9KS9hKyKKyAWt6Smlxt7xlgLd6i3vDXzYsFBKaUpKqSSlVNKpU6PXBZOkzWwpbNXU1LRAayRpU/n4NmIAtwKLUkrXbaHYTOCc2m8lHg58mlJa1tS6JRW+iooKfvCDHzB8+HCGDBnCqlWruPLKKxk8eDBDhgyhqqqKKVOmMHv2bAYPHszKlSvp06cPZ511Ftdeey0LFixg4MCBHH744UybNm2TfX/++eeMHj2aIUOGcNppp7F+/XpKS0uZM2cOkBsBq6qqYurUqZxxxhkcf/zxjBw5kptuuokjjzyScePGtcSfRFIrk49vIw4EzgYWRsT82nWXA90BUko3Aw8D3wcWA38DzstDvZIKVUoQX84+WLt2LbNnz+aee+7hhhtu4IMPPqCiooJFixZxzTXXcNlll/Hee+/VhamlS5fy3HPPscsuuzBy5EimT59O165dGTRoEKeddlrdfm+55RZGjhzJ6NGjuemmm7jvvvu22KROnTpx1113MX78eNauXctTTz3Fcccdx6pVq/jmN7+Z3d9CUqvX5LCVUnqGxudk1S+TgB83tS5JbUBpKaxZA2VlucCVEoesXg2lpfQdPZrLLruMoqIiBg8eDECXLpt/sblXr17ssssuAKxevZqN91ndd999WbFiRV25RYsWMW/ePH73u9+xdu1aRo8eTdQLebm3rpyDDjoIgL322muTx6tXrzZsSfpK2+29ESW1QSnlglZ5eW65rAxuuIEF8+bBoEEsmD+fc889l48//pjJkycDsH79elasWMGGDRvqdtOu3ZczJIqLi6mqqqJr1668++67dO7cuW5br169GDp0KKNGjarb1w033MCyZctIKfHGG2/Ula0fwrYUyCSpMYYtSduPiFzAglzgqg1dRT16MOytt1g7fz73338/N998M4MHDyYiGD16NGPHjmXVqlWccsopTJkyZZNdXnnllZxxxhls2LCBH//4xxQVFdVtGz9+POeffz433ngjKSWuueYaTj75ZE466SRmzpzJN77xjWbruqTCFdvr/8pKSkpSZWVlSzdDUktICWpHpyqAOZdfzlVXX92iTZKkrxIR81JKJY1t80bUkrYvKcHEiZuumz07t16SWiHDlqTtx8agVV4OEyZATQ2DJ0zgqpdfzq03cElqhZyzJWn7EQHFxbmgtfHbiBvncBUXb3I5CElqLZyzJWn70+A6W5stS9J2xjlbklqXhsHKoCWpFTNsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFuSJEkZMmxJkiRlyLAlSZKUIcOWJElShgxbkiRJGTJsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFuSJEkZMmxJkiRlKC9hKyJui4gVEfH6FrYPjohPI2J+7c8V+ahXkiRpe9chT/uZClwP3PEVZZ5OKY3IU32SJEmtQl5GtlJKTwGr8rEvSZKkQtKcc7YGRMSCiHgkIg5sxnolSZJaTL5OI27NK8A+KaXPIuL7wB+Bng0LRcR4YDxA9+7dm6lpkiRJ2WmWka2U0p9TSp/VPn4YKIqIjo2Um5JSKkkplXTq1Kk5miaplZg/fz633norAIMGDWrh1kjStmuWka2I2BNYnlJKEdGfXMj7pDnqllQY+vbtS9++fVu6GZL0teUlbEXEDGAw0DEilgL/ChQBpJRuBk4BLoiIauBz4PSUUspH3Wo7ampqaNfOS8O1FdXV1Zx99tl88MEHdO3albFjx1JRUcFVV13V0k2TpK8lL2ErpTR6K9uvJ3dpCLUlKUFE7cPEhRdcwNv//d/svPPOjBs3jqlTp1JTU8OqVauYNWsWu+yyCxdeeCFvv/02O++8M9OmTWPBggVcd911uedfeCFLlixh6tSpHHXUUbz44ovMmDGDiRMncvfdd1NdXc1xxx3HE0880cIdV5PUvm4eeOABDjjgAGbcdRdXXX01n3ziYLik1qm5JsirrSkthTVroKwMInjowQfpvnAhNx17LI8cdhjz588H4MEHH+Tqq6/m8ccfp127dnTv3p2bbrqJRx55hJtvvpkBAwbwxRdf8Oijj1JdXc2gQYN49tlnqays5MUXX6RLly789a9/5S9/+QvPPfccxxxzTMv2W01T73XzzjvvcOghh8DEiZR8/DHzaoO7JLU2hi3lX0q5D8zy8txyWRmLrr2Wu597jllLllA9Zw7r1q3juOOOA6Br166sWbOG5cuXc/fddzNr1iyqq6sZMGAAAIceeigAH3/8Md27d6d9+/abzN05+eST+dOf/sQTTzzBpEmTmrevyp8Gr5v9Bgxg3tVXc/wLL1A5YAD7H388r7/xRgs3UpK+PsOW8i8iN6IFuQ/O8nJ6AecccQSXzJ0LEcyePZu5c+fWPSWlRK9evTjnnHO45JJLAFi/fj3PPvts3Tytjh078v7771NTU8Nrr71W99xRo0Zx5plnsn79evbbb79m66byrMHr5qTycs4CjtxrL7p068ZhHTf7ArMktQrONlY26n9wAiOBqoMPZsjQoQwZMoTPP/98s6eMHDmSqqoqhgwZwpAhQ3jkkUc22d6hQwfOPfdcvve973HXXXdRVFQEwO67785OO+3E8OHDM+2SmkG9100RcA/w1NKl3HPPPRx77LF1k+OfeeaZlmujJH1NjmwpGynBxIl1iwFM7tABHn+8btL8yJEjARgzZkxducmTJ2+2q8GDB9c9HjduHP/4j//Iiy++yG233Va3vqioiFNPPTW/fVDza/C6AXLLtXP/JKk1cmRL+bfxA7O8HCZMgJqa3O/y8tz6Jlz1Y/LkyRx11FH89Kc/rTvdOH78eDp37kyXLl3y1QO1hAxfN5LUkhzZUv5FQHFx7oNy44jExlOKxcVNGqGYOHEiExuMfEyZMqUprdX2IsPXjSS1pNhery1aUlKSKisrW7oZaop619lqdFlqjK8bSa1QRMxLKZU0ts3TiMpOww9IPzC1LXzdSCowhi1JkqQMGbYkSZIyZNiSJEnKkGFLkiQpQ4atBubPn8+tt976lWWqqqo2uRDn1kydOpWampomtkySJLVGhq0G+vbty9ixY/O6z8bCluFLkqS2wbDVQEVFBZMmTaJPnz6cc8459OnTh/nz5wNwxRVXcMQRR3DdddfVlR80aBDw5WjXF198wYgRIzj66KM59dRTeemll5g/fz5Dhw7lzjvvZMyYMVx00UUMGzaMCy64gNdffx2A3/zmN9x///3N32FJkpQpryAPjV5E8aOPPuLFF19k3rx53H777fzDP/wDL730Ek8//TR33XUXjz32WKO7eu+99+jYsSMPPfQQKSUigr59+zJnzhw6dOjA448/zsCBA7n++ut55plnuPvuu7nqqqt45JFH+NOf/tRMHZYkSc3Fka3S0k3vu5YSzJ7N/jvuyE477UTXrl1Zs2YNS5Ys4eCDDwagX79+m+1m45X4999/f3r37s2ZZ55J2cZbjTSw8fkDBw7khRdeoKqqii5durDTTjvlv3+SJKlFte2wlRKsWbPpjW5vuAFefpmorq4LYCkl9tlnHxYuXAjAq6++WreLtWvXAtRtW7duHRMnTmT69Ok8+uijLF++nKKiIjZs2FD3nHbtcn/2iKB///780z/9E6effnqzdFmSJDWvtn0asf6NbsvLcz8A/+t/wQ47bHJqsUuXLvTr148jjjiCPn361K0//vjjGTRoEIcddhgAS5YsYezYsVRXV7PffvvRuXNnjj/+eE488UTGjRu3WRPOPPNMBg8ezIwZM7LrpyRJajHeiBpyI1jt6g3y1dQ02/3Y3nzzTW688Uauv/76ZqlPkiTlnzei/iop5U4h1ld/DleGnn76acaOHcvFF1+ceV2SJKlltO2wtTFolZfDhAm5Ea0JEzadw5WhI444gueff57vfOc7mdYjSZJajnO2iotzAausbNM5XMXFzXYqUZIkFS7nbEGj19kyaEmSpG3lnK2taRisDFqSJClPDFuSJEkZMmxJkiRlyLAlSZKUobyErYi4LSJWRMTrW9geEfHbiFgcEa9FxKH5qFeSJGl7l6+RranAsK/YPhzoWfszHrgpT/VKkiRt1/IStlJKTwGrvqLICcAdKecFoDgiuuSjbkmSpO1Zc83Z6gq8X295ae06SZKkgtZcYauxC1dtdjXViBgfEZURUbly5cpmaJYkSVK2mitsLQW61VveG/iwYaGU0pSUUklKqaRTp07N1DRJkqTsNFfYmgmcU/utxMOBT1NKy5qpbkmSpBaTlxtRR8QMYDDQMSKWAv8KFAGklG4GHga+DywG/gacl496JUmStnd5CVsppdFb2Z6AH+ejLkmSpNbEK8hLkiRlyLAlSZKUIcOWJElShgxbkiRJGTJsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFuSJEkZMmxJkiRlyLAlSZKUIcOWJElShgxbkiRJGTJsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFtqkoqKCiZNmtTSzZAkabtl2BKQTWj6yU9+AsDUqVOpqanJ674lSWotDFutTUp1D88//3wWvfkmAL/97W/5wx/+wMiRIzn66KO58MILASgtLWXcuHEcc8wxjBs3DoCVK1duVq6srIw777yTgw8+mLFjxzJ16lRuueWWun1UVFSQUuKCCy5gyJAhHH/88axevXqTpp166qkcddRRHHfccfz5z39m8uTJgGFLktS2GbZak9JSmDixLnCdMmoU940dC6WlPProozz33HNcdtllPPnkk+y22248//zzABx44IHMmTOH9957jzVr1vDLX/7yy3K77srzzz/PxIkTOfPMM+nSpQvvvvsuN954IytWrAByYQmgpKSE7t27c/jhh1NUVMTNN9/Mz372MyAXtD788EN23HFHfvCDH3DPPfcwaNAgXnrpJebPn8/QoUO58847m/1PJklSS+vQ0g3QNkoJ1qyB8vLcclkZQx9+mF+98AI/6t2b3XbbjbfffptLL72UiOCzzz6jf//+ABx00EEA7LXXXnz66acsWrQoV27JEj77/HP69+/Ptzp25OGHH6boo4+YevLJ/Oi11zZrws4778ztt99eN6K155570qlTJwBuvfVWLr30UmbPns21115bN4rWv39/+vbty5w5c+jQwZebJKnt8dOvtYiAsrLc4/JyKC+nA9DjgAP4t91358Sjj+all17irLPOol+/fgBUV1ezcOFCIqJuNyklevXqxVlnnkm/adOgvJzqp57iX3fbjcVvvskl69dz4A47sMMOO9SNbH322WcADBgwgKqqKnbffXd23HFHDj30UPbYYw9qamr44Q9/yFNPPUWXLl347ne/S6p3ulOSpLYsL2ErIoYB5UB74JaU0i8bbB8D/BvwQe2q61NKt+Sj7jZlY+DaOLoFnHLttZx62mksW7aMY445hvHjx/Ppp5/Srl07fv/73ze6m8svv/zLct268fvJk5kKfBOY8j/+B+9+8gnf/e53efzxxxkxYkRd2JowYQJ9+/blm9/8Ju3bt+eRRx7hF7/4BXPnzmWHHXagZ8+erFmzhqVLl3LooYfW1VdUVMSGDRsc2ZIktUnR1BGIiGgP/DdwLLAUeBkYnVJ6s16ZMUBJSumibd1vSUlJqqysbFLbCk5KuTlb9cIWEybkAli90auvvc927agA5gClX3zB6aNH85Of/ISLL76Yvn37snDhQl555RUA9tlnH/74xz+y6667MmDAAD7++GM+++wzhg0bxq677kq3bt3o2rUrpaWlDBo0iGeeeYbf/OY3zJo1i3HjxjFq1Kim/hUkSdruRMS8lFJJo9vyELYGAKUppf9du3wZQErpmnplxmDYapr6QWtjwGq4/HUDVxbhTZKkNuirwlY+vo3YFXi/3vLS2nUNjYqI1yLivojolod625YIKC7eNAyVleWWi4ubFrQmTICamtzv8vJNvvEoSZKaJh+TaBr7lG/4Sf0gMCOltC4i/hG4HRiy2Y4ixgPjAbp3756HphWY0tJcCNoYrDYGrr9nFGpL4Q3+vvAmSZIa1SynERuUbw+sSint8VX79TRiM6kf3hpbliRJW5X1acSXgZ4RsW9E7ACcDsxs0IAu9RZHAovyUG9BGDx4cMs2oGGwMmhJkpRXTT6NmFKqjoiLgFnkLv1wW0rpjYi4EqhMKc0ELo6IkUA1sAoY09R625KamhratfNi/5IktUZ5+QRPKT2cUvpOSunbKaWra9ddURu0SCldllI6MKXUJ6V0dErprXzU2yxqT7M2vC/gJ598wrhx4zjqqKMYPnw4AIMGDap72sYRq2uuuYajjjqKww47jFdffRWAhx56iH79+vGjH/2I6upqABYsWMDAgQM5/PDDmTZtGgBjxozhoosuYtiwYc3VW0mSlGcOl3yVevcifOihh+jerRtPHHwwFxUXM2XKFDp37szcuXP5r//6ry3uYsKECcydO5fp06fz61//GsgFsLlz5zJp0iQ++ugjAP7lX/6F6dOn8/TTTzN58mTWr18PwMCBA3nssccy76okScqGl/Tekgb3IlzUpQt3l5Ux6+OPqe7ShWfvuosHH3wQYLNTfPW/dHDnnXcyffp02rVrV3fbnHbt2rHrrruy66671t1bcPXq1fTo0QOAfffdt+5WORtvvSNJklonw9aWNLgXYS/gHOCS2ksl/OG++3jhhRcYMWJE3ZyqlBLr1q3j7bffrtvNjTfeyKuvvso777zD+eefD+TmYP31r39l9erVrFy5EoDi4mKqqqro2rUr7777Lp07dwY2D3KSJKl18ZP8q9QLXCOBKmDIa68xZOhQdtxxR5YtW8aRRx7JiBEjgNwcq0GDBvGHP/yhbhf9+/fnyCOP5D/+4z/q1v3zP/8zRx55JL/4xS/Yc889Abjyyis544wzGDRoED/+8Y8pKipqrl5KkqQMNfk6W1nZLq6z5e1sJEnSNsj6OluFydvZSJKkPHDO1pZ4OxtJkpQHnkbcGm9nI0mStsLTiE3h7WwkSVITGLYkSZIyZNiSJEnKkGFLkiQpQ4YtSZKkDBm2JEmSMmTYkiRJypBhS5IkKUOGLUmSpAwZtiRJkjJk2JIkScqQYUuSJClDhi1JkqQMGbYkSZIyZNiSJEnKkGFLkiQpQ4YtSZKkDBm2JEmSMmTYkiRJypBhS5IkKUOGLUmSpAzlJWxFxLCIeDsiFkfEpY1s3zEi7qnd/mJE9MhHvZIkSdu7JoetiGgP3AAMBw4ARkfEAQ2KjQVWp5T2B8qAXzW1XkmSpNYgHyNb/YHFKaV3U0pfAHcDJzQocwJwe+3j+4ChERF5qFuSJGm7lo+w1RV4v97y0tp1jZZJKVUDnwLfarijiBgfEZURUbly5co8NE2SJKll5SNsNTZClf6OMqSUpqSUSlJKJZ06dcpD0yRJklpWPsLWUqBbveW9gQ+3VCYiOgB7AKvyULckSdJ2LR9h62WgZ0TsGxE7AKcDMxuUmQmcW/v4FOCJlNJmI1uStl9VVVU88cQTX/t5t912WwatkaTWo8lhq3YO1kXALGARcG9K6Y2IuDIiRtYWuxX4VkQsBv4vsNnlISRt3wxbkvT36ZCPnaSUHgYebrDuinqP1wL/Jx91Scq/6upqzj77bD744AO6du3K0KFDARg3bhylpaUMHjyYKVOm8Oyzz/L8889z6623ct5557H77ruzfPlyZsyYQUQwadIkpk2bRkVFBRUVFey1114sXLiQwYMHM3nyZHr37t3CPZWk5ucV5KW2rPZs/gMPPMABBxzAU3PncuCBB/LJJ59sVnT8+PGcffbZPP744wB89NFH3H///ZSXl/OrXzV+6bzx48fTu3dvKioqDFqS2izDltRWlZbCxImQEu+88w6HHnIITJxIyVtvsXbt2rpiW5pe2bt3bzp06EDfvn1ZvHgx9S+d55RMSfqSYUtqi1KCNWugvBwmTmS/ffdl3tVXQ3k5le++S6/vfIdly5YBsHDhQgCKiorYsGFD3S5ef/11NmzYwIIFC/j2t7/NHnvswUcffbTJcwC8frGkts6wJbVFEVBWBhMmQHk5J51+Om+88AJH7rUXC7t14/gRI3j00UcZOXJk3VMOOuggnn32WU477TQAOnfuzIknnsjFF1/Mz372M4qLi+nevTvHHHMMb775Zt3zunXrxqhRo3jrrbeavZuStD2I7XW4v6SkJFVWVrZ0M6TClhK0q/d/rpqaXBDbiqqqqrrJ8JIkiIh5KaWSxrY5siW1VSnl5mzVVzuHS5KUP4YtqS3aGLTKy3OnEmtq6k4pbkvg6tGjh6NakrSN8nKdLUmtTAQUF+cCVlnZl3O4ILfeSe2SlDfO2ZLaspQ2DVYNlyVJ28Q5W5Ia1zBYGbQkKe8MW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFuSJEkZMmxJkiRlyLAlSZKUIcOWJElShgxbkiRJGTJsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFuSJEkZMmxJkiRlqElhKyK+GRGzI+L/1f7+xhbKbYiI+bU/M5tSpyRJUmvS1JGtS4HHU0o9gcdrlxvzeUqpb+3PyCbWKUmS1Go0NWydANxe+/h24MQm7k+SJKmgNDVs/UNKaRlA7e/OWyi3U0RURsQLEWEgkyRJbUaHrRWIiDnAno1s+vnXqKd7SunDiNgPeCIiFqaU3mmkrvHAeIDu3bt/jd1LkiRtn7YatlJKx2xpW0Qsj4guKaVlEdEFWLGFfXxY+/vdiKgADgE2C1sppSnAFICSkpK0TT2QJEnajjX1NOJM4Nzax+cCf2pYICK+ERE71j7uCAwE3mxivZIkSa1CU8PWL4FjI+L/AcfWLhMRJRFxS22Z/wlURsQC4Englyklw5YkSWoTtnoa8auklD4BhjayvhIYV/v4OaB3U+qRJElqrbyCvCRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFuSJEkZMmxJkiRlyLAlSZKUIcOWJElShgxbkiRJGTJsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGDFuSJEkZMmxJkiRlyLAlSZKUIcOWJElShgxbkiRJGTJsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpQhw5YkSVKGmhS2IuL/RMQbEVETESVfUW5YRLwdEYsj4tKm1ClJktSaNHVk63XgZOCpLRWIiPbADcBw4ABgdEQc0MR6JUlSC6uoqGDSpEl53efUqVO55ZZb8rrPltaksJVSWpRSensrxfoDi1NK76aUvgDuBk5oSr2SJKn1qampafRxoevQDHV0Bd6vt7wUOKwZ6pUkSRlbsGABw4cPZ926dcyYMYMzzjiD9evX06lTJ+69917ef/99zjvvPL71rW/x/e9/nzvuuIP+/fvz4Ycf8vvf/54f/vCHLF++nE6dOjFt2rS6/S5evJhzzjmHHXfckWOPPZbLL7+8BXvZNFsNWxExB9izkU0/Tyn9aRvqiEbWpS3UNR4YD9C9e/dt2LUkSWp2KUHkPt7Xrl3L7Mce45577+W2227joYceYuedd2bSpEk88cQT9OzZkxUrVjBnzhzat2/PHXfcwUknncSAAQOYPHkyI0eOZPTo0dx0003cd999dVVUVFQwfvx4xowZQ0qNxoZWY6thK6V0TBPrWAp0q7e8N/DhFuqaAkwBKCkpad1/WUmSClFpKaxZA2VlABzSty9MnEjf6mpmr13L2LFj+eCDD1i+fDk9e/akZ8+e9OnTh/bt29ftol+/fgAsWrSIefPm8bvf/Y61a9cyevRo9thjDwBOPfVUSktLOfPMMznrrLMYPnx4s3c1X5rjNOLLQM+I2Bf4ADgdOKMZ6pUkSfmUUi5olZfnlk84gQX33gvvvceC4cPZ93vfY311NXfddRc///nP60ak2rXbdIr4xuVevXoxdOhQRo0aBcD69euZPn06AEVFRVx33XV88cUXDBw4sFWHraZe+uGkiFgKDAD+KyJm1a7fKyIeBkgpVQMXAbOARcC9KaU3mtZsSZLU7CJyI1oTJuQC15AhFL33HsP22Ycb//Y3zjr7bGbOnMmIESOoqqra6u7Gjx/PAw88wNChQxkyZAivvPJK3baZM2dyxBFHMGDAAM44o3WP0cT2eh60pKQkVVZWtnQzJElSQylB/dGqmpq6OVxtVUTMSyk1es1RryAvSZK2XUowceKm6yZOzK1XowxbkiRp22wMWuXluVOJNTVfnlI0cG1Rc0yQlxLHWMIAAAdASURBVCRJhSACiotzAaus7Ms5XJBb38ZPJW6Jc7YkSdLXU+86W40ut0HO2ZIkSfnTMFi18aC1NYYtSZKkDBm2JEmSMmTYkiRJypBhS5IkKUOGLUmSpAwZtiRJkjJk2JIkScqQYUuSJClDhi1JklTwKioqmDRp0jaXr6qqYsyYMXmp27AlSZKUIW9ELUmSClODezYuWLCA4cOHs27dOn79619zySWXsPvuu7N8+XJmzJjBvvvuyxVXXMGTTz7JIYcckrdmOLIlSZIKT2kpTJyYC1wAKbF2wQIeOewwfvSjH/HYY4/x0Ucfcf/991NeXs6vfvUrli1bxksvvcTTTz/N4YcfnremGLYkSVJhSQnWrIHy8i8D1w03cMj778OaNfTt04c5c+bQu3dvOnToQN++fVm8eDFLlizh4IMPBqBfv355a45hS5IkFZYIKCuDCRNygatdO7j/fhZ07w5lZSx47TWGDh3K66+/zoYNG1iwYAHf/va32WeffVi4cCEAr776at6a45wtSZJUeDYGrvLyulVFvXszbPhw1q5dy7//+78za9YsTjzxRFauXMn06dPp0qUL/fr144gjjqBPnz55a4phS5IkFZ6UcqcQaw0GBu+/fy6ARVBVVcXee+/NtGnTNnnaVVddlfemeBpRkiQVlo1Bq7w8dyqxpubLU4r1J803E0e2JElSYYmA4uJcwKodyaKsLLetuBgi6NGjx2ajWpk1JzVzuttWJSUlqbKysqWbIUmSWqsG19nabDmPImJeSqmksW2eRpQkSYWpYbDKKGhtjWFLkiQpQ4YtSZKkDBm2JEmSMmTYkiRJypBhS5IkKUOGLUmSpAwZtiRJkjK03V7UNCJWAktauh0Z6gh83NKNaCH2vW2y722TfW+b2mLf90kpdWpsw3YbtgpdRFRu6Uqzhc6+2/e2xr7b97amLfe9MZ5GlCRJypBhS5IkKUOGrZYzpaUb0ILse9tk39sm+942teW+b8Y5W5IkSRlyZEuSJClDhq0MRcSwiHg7IhZHxKWNbB8TESsjYn7tz7iWaGcWIuK2iFgREa9vYXtExG9r/zavRcShzd3GrGxD3wdHxKf1jvsVzd3GrEREt4h4MiIWRcQbETGhkTIFeey3se8FeewjYqeIeCkiFtT2/ReNlNkxIu6pPe4vRkSP5m9p/m1j3wv5vb59RLwaEQ81sq0gj/nfo0NLN6BQRUR74AbgWGAp8HJEzEwpvdmg6D0ppYuavYHZmwpcD9yxhe3DgZ61P4cBN9X+LgRT+eq+AzydUhrRPM1pVtXAJSmlVyJiN2BeRMxu8Lov1GO/LX2Hwjz264AhKaXPIqIIeCYiHkkpvVCvzFhgdUpp/4g4HfgVcFpLNDbPtqXvULjv9ROARcDujWwr1GP+tTmylZ3+wOKU0rsppS+Au4ETWrhNzSal9BSw6iuKnADckXJeAIojokvztC5b29D3gpVSWpZSeqX28V/IvQl3bVCsII/9Nva9INUey89qF4tqfxpOCD4BuL328X3A0IiIZmpiZrax7wUpIvYGjgdu2UKRgjzmfw/DVna6Au/XW15K42+8o2pPpdwXEd2ap2nbhW39+xSqAbWnHR6JiANbujFZqD1lcAjwYoNNBX/sv6LvUKDHvvZ00nxgBTA7pbTF455SqgY+Bb7VvK3Mxjb0HQrzvf43wM+Ami1sL9hj/nUZtrLTWHpv+L+dB4EeKaWDgTl8+T+AtmBb/j6F6hVyt3XoA0wG/tjC7cm7iNgVuB/4aUrpzw03N/KUgjn2W+l7wR77lNKGlFJfYG+gf0Qc1KBIwR73beh7wb3XR8QIYEVKad5XFWtkXUEc86/LsJWdpUD9/73sDXxYv0BK6ZOU0rraxd8D/ZqpbduDrf59ClVK6c8bTzuklB4GiiKiYws3K29q563cD0xPKf1nI0UK9thvre+FfuwBUkprgApgWINNdcc9IjoAe1Bgp9u31PcCfa8fCIyMiCpy02SGRMS0BmUK/phvK8NWdl4GekbEvhGxA3A6MLN+gQbzVEaSm+PRVswEzqn9ZtrhwKcppWUt3ajmEBF7bpy3EBH9yf07/KRlW5Uftf26FViUUrpuC8UK8thvS98L9dhHRKeIKK59vDNwDPBWg2IzgXNrH58CPJEK4EKP29L3QnyvTyldllLaO6XUg9zn2xMppbMaFCvIY/738NuIGUkpVUfERcAsoD1wW0rpjYi4EqhMKc0ELo6IkeS+xbQKGNNiDc6ziJgBDAY6RsRS4F/JTRwlpXQz8DDwfWAx8DfgvJZpaf5tQ99PAS6IiGrgc+D0AnoDGgicDSysncMCcDnQHQr+2G9L3wv12HcBbq/9FnY74N6U0kMN3u9uBe6MiMXk3u9Ob7nm5tW29L1g3+sbaiPH/GvzCvKSJEkZ8jSiJElShgxbkiRJGTJsSZIkZciwJUmSlCHDliRJUoYMW5IkSRkybEmSJGXIsCVJkpSh/w99PmglR16oiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure words matches those in function above\n",
    "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait',\n",
    "         'oil', 'output', 'petroleum','venezuela']\n",
    "\n",
    "plot_embeddings(M_reduced, word2Idx, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare this to the co-occurrence matrix plot: groupings appear to be a little better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "- Distance between words can be used to quantify similarities of those words\n",
    "- Cosine Similarity between vectors p and q can be expressed in terms:\n",
    "    $$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
    "    \n",
    "\n",
    "### Polysemous Words\n",
    "- Words that can express more than one meaning\n",
    "- Identify the top 10 more similar words using cosine similarity:\n",
    "    - As noted above, proximal words theoretically would have greater similarity\n",
    "- wv_from_bin.most_similar(word) is the funciton used to get the top 10 similar words\n",
    "    - ranks all words in vocabulary with respect to their cosine similarity to given word\n",
    "    - GenSim documentation: https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summer', 0.7650764584541321),\n",
       " ('winter', 0.6890672445297241),\n",
       " ('autumn', 0.6658838987350464),\n",
       " ('springtime', 0.653981626033783),\n",
       " ('midsummer', 0.5891797542572021),\n",
       " ('Punxsutawney_Phil_predicts', 0.550977349281311),\n",
       " ('Spring', 0.550716757774353),\n",
       " ('week', 0.5474802255630493),\n",
       " ('fall', 0.5415068864822388),\n",
       " ('summertime', 0.5398696660995483)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find polysemous words using .most_similar function:\n",
    "\n",
    "# .most_similar() takes a word from the corpus, based on probabilities\n",
    "#      defaults topn is 10, see link above for other function parameters\n",
    "# Note: depending on corpus size, can take some time to run\n",
    "\n",
    "# testing different words: leaves, scoop, run, king, challenge\n",
    "wv_from_bin.most_similar('spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonym and Antonyms\n",
    "\n",
    "- Can be more convenient to think of cosine distance: 1-cosine_similarity\n",
    "- Using three words (w1, w2, w3) where:\n",
    "    - w1 and w2 are synonyms\n",
    "    - w1 and w3 are antonyms\n",
    "    - cosine distance (w1, w3) < cosine distance (w1, w2)\n",
    "        - ex: w1='happy' is closer to w3='sad' than to w2='cheerful'\n",
    "- uses wv_from_bin.distance() function\n",
    "- Gensim documentation: https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms big, grand have cosine distance 0.7428221702575684\n",
      "Antonyms big, small have cosine distance 0.5041321516036987\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# specify w1, w2, w3 for testinabsg\n",
    "w1 = 'big'\n",
    "w2 = 'grand'\n",
    "w3 = 'small'\n",
    "\n",
    "# get cosine distance between words\n",
    "w1w2_dist = wv_from_bin.distance(w1, w2)\n",
    "w1w3_dist = wv_from_bin.distance(w1, w3)\n",
    "\n",
    "print('Synonyms {}, {} have cosine distance {}'.format(w1, w2, w1w2_dist))\n",
    "print('Antonyms {}, {} have cosine distance {}'.format(w1, w3, w1w3_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that 'big'-'grand' cosine distance is larger than 'grand'-'small' cosine distance implying that 'grand' is more similar to 'small' than is 'big'\n",
    "    - this may be because polysemous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Analogies with Word Vectors\n",
    "\n",
    "- word2vec vectors have had some success solving analogies\n",
    "    - ie: man:king :: woman:x, what is x\n",
    "- Using .most_similar function, we find:\n",
    "    - most similar words in the positive list and \n",
    "    - most disimilar words in negative list\n",
    "        - answers will be the word ranked most similar (largest numerical value)\n",
    " GenSim documentations: https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071),\n",
      " ('monarch', 0.6189674139022827),\n",
      " ('princess', 0.5902431607246399),\n",
      " ('crown_prince', 0.5499460697174072),\n",
      " ('prince', 0.5377321243286133),\n",
      " ('kings', 0.5236844420433044),\n",
      " ('Queen_Consort', 0.5235945582389832),\n",
      " ('queens', 0.5181134343147278),\n",
      " ('sultan', 0.5098593235015869),\n",
      " ('monarchy', 0.5087411999702454)]\n"
     ]
    }
   ],
   "source": [
    "# Solve analogy\n",
    "\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "\n",
    "# get first in list (highest number)\n",
    "#pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'king'], negative=['man'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('carpenter', 0.5728063583374023)\n"
     ]
    }
   ],
   "source": [
    "# Solve analogy 2\n",
    "# stone:mason :: wood:x  (x should be carpenter)\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['wood', 'mason'], negative=['stone'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Bias in Word Vectors\n",
    "\n",
    "- it's important to be cognizant of gender, race, sexual orientation biases in word embeddings\n",
    "- here we look at \n",
    "    - terms most similar for 'woman' & 'boss' and most dissimilar to 'man'\n",
    "    - terms most similar to 'man' and 'boss' and most dissimilar to 'woman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bosses', 0.5522644519805908),\n",
      " ('manageress', 0.49151360988616943),\n",
      " ('exec', 0.45940813422203064),\n",
      " ('Manageress', 0.45598435401916504),\n",
      " ('receptionist', 0.4474116563796997),\n",
      " ('Jane_Danson', 0.44480544328689575),\n",
      " ('Fiz_Jennie_McAlpine', 0.44275766611099243),\n",
      " ('Coronation_Street_actress', 0.44275566935539246),\n",
      " ('supremo', 0.4409853219985962),\n",
      " ('coworker', 0.43986251950263977)]\n",
      "\n",
      "[('supremo', 0.6097398400306702),\n",
      " ('MOTHERWELL_boss', 0.5489562153816223),\n",
      " ('CARETAKER_boss', 0.5375303626060486),\n",
      " ('Bully_Wee_boss', 0.5333974361419678),\n",
      " ('YEOVIL_Town_boss', 0.5321705341339111),\n",
      " ('head_honcho', 0.5281980037689209),\n",
      " ('manager_Stan_Ternent', 0.525971531867981),\n",
      " ('Viv_Busby', 0.5256162881851196),\n",
      " ('striker_Gabby_Agbonlahor', 0.5250812768936157),\n",
      " ('BARNSLEY_boss', 0.5238943099975586)]\n"
     ]
    }
   ],
   "source": [
    "# Here `positive` indicates the list of words to be similar to and \n",
    "#         `negative` indicates the list of words to be most dissimilar from.\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'boss'], negative=['man']))\n",
    "print()\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'boss'], negative=['woman']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lesbian', 0.5497785806655884),\n",
      " ('homosexual', 0.5407663583755493),\n",
      " ('homosexuals', 0.5150601863861084),\n",
      " ('gays', 0.509407639503479),\n",
      " ('hetro', 0.501957893371582),\n",
      " ('homophobia', 0.48830151557922363),\n",
      " ('heterosexual', 0.4863852858543396),\n",
      " ('gayness', 0.48594969511032104),\n",
      " ('queer', 0.4809682071208954),\n",
      " ('homosexuality', 0.4786364734172821)]\n",
      "\n",
      "[('consecutive', 0.4799199104309082),\n",
      " ('staight', 0.41569390892982483),\n",
      " ('gut_wrencher', 0.39936715364456177),\n",
      " ('loves', 0.39820700883865356),\n",
      " ('outbattle', 0.3927672505378723),\n",
      " ('heartbreaker', 0.39253556728363037),\n",
      " ('loved', 0.3885837197303772),\n",
      " ('loooooove', 0.38792747259140015),\n",
      " ('passion', 0.3833823800086975),\n",
      " ('Highland_Lone_Tree', 0.3827238082885742)]\n"
     ]
    }
   ],
   "source": [
    "# Find some other words where bias appears in the results\n",
    "\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['gay', 'love'], negative=['straight']))\n",
    "print()\n",
    "pprint.pprint(wv_from_bin.most_similar(positive=['straight', 'love'], negative=['gay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
