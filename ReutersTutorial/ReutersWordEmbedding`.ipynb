{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters 'Crude' Article Analysis\n",
    "\n",
    "- Based on code and procedure from the Stanford NLP Deep Learning\n",
    "    - found in DS_Recipes/NLP/Stanford Class\n",
    "    - this file will exclude the instruction and sample code found in the tutorial and only focus on the analysis of the Reuters data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors\n",
    "\n",
    "- Word vectors and word embeddings are used interchangeably\n",
    "    - specify a word's meaning by changing from high one-dimensional space to a continuous vector that is a much lower dimension\n",
    "        - This is like taking the word 'run' and encoding as a vector of continuous numbers such as:\n",
    "            [1.002, -2.033, -9.881, 13.032, ..., 2.818] \n",
    "            \n",
    "- Word vectors center around idea that similar words have similar context, and thus will be relatively proximal to a shared subset of words\n",
    "\n",
    "## In this script:\n",
    "- Two main types of word vectors / word embeddings used in this script:\n",
    "    - Count-based word vectors: co-occurrence matrix\n",
    "    - Prediction-based word vectors: word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Global Variables\n",
    "- this may not be all inclusive as more may be more approriately run at beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 5\n",
    "\n",
    "import pprint\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "import nltk\n",
    "## download preloaded dataset (10,788 documents, 1.3 mil words)\n",
    "## https://www.nltk.org/book/ch02.html\n",
    "## uncomment download line below if not already downloaded\n",
    "# nltk.download('reuters') \n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "\n",
    "## Used for dimension reduction on co-occurrence matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## Generate global variablesabs\n",
    "## Start and End tokens will be applied to beginning\n",
    "##   and end of each document\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Corpus\n",
    "- Reuters corpus contain 90 categories that are split into train and test\n",
    "- for this project, the Reuters corpus will be subset to only include the \"Crude\" category which includes articles about oil, gas, etc\n",
    "- https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters:\n",
    "    category is a string referring to the Reuters category type\n",
    "Return: \n",
    "    a list of lists: a list of the words from each file\n",
    "'''\n",
    "\n",
    "\n",
    "def read_corpus(category='crude'):\n",
    "    files = reuters.fileids(category)\n",
    "    return[[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review article in the Reuters corpus selected for crude category\n",
    "\n",
    "# Remove and run to test-----------\n",
    "#my_corpus = read_corpus()\n",
    "#pprint.pprint(my_corpus[:1], compact=True, width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Distinct Words\n",
    "- try to avoid for loops since they are slower\n",
    "- instead use set comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters:\n",
    "    corpus: list of list from read file defined above\n",
    "Return:\n",
    "    corpus_words: list of string, distinct words across corpus, sorted\n",
    "    num_corpus_words: number of distinct words across corpus\n",
    "'''\n",
    "\n",
    "def distinct_words(corpus):\n",
    "    corpus_words_dist = sorted(list(set([word for doc in corpus for word in doc])))\n",
    "    corpus_words_dist_cnt = len(corpus_words_dist)\n",
    "    return corpus_words_dist, corpus_words_dist_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run distinct_words function\n",
    "#    print last 50 unique words and the number of unique words in corpus\n",
    "\n",
    "# Remove and run to test-----------\n",
    "#corpus_words_dist, corpus_words_dist_cnt = distinct_words(my_corpus)\n",
    "#print(corpus_words_dist[-50:])\n",
    "#print(corpus_words_dist_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Analysis Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count-Based Word Vector: Co-occurrence matrix\n",
    "\n",
    "- count of how often words co-occur with each other in a document based on a specified window\n",
    "    - a window of size $n$ means $n$ preceeding words and $n$ subsequent words in the document where $w_i$ is the word of interest\n",
    "        - $w_{i-n} \\dots w_{i-1}$, $w_i$, $w_{i+1} \\dots w_{i+n}$\n",
    "        \n",
    "        - iterating over the document in word by word fashion, each word becomes $w_i$ and the number of times $w_i$ occurs with other words in the window $n$ are counted and entered in a symetric matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
    "\n",
    "    Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
    "          number of co-occurring words.\n",
    "\n",
    "          For example, if we take the document \"START All that glitters is not gold END\" with window size of 4,\n",
    "          \"All\" will co-occur with \"START\", \"that\", \"glitters\", \"is\", and \"not\".\n",
    "\n",
    "    Params:\n",
    "        corpus (list of list of strings): corpus of documents\n",
    "        window_size (int): size of context window\n",
    "    Return:\n",
    "        M (numpy matrix of shape (number of corpus words, number of corpus words)): \n",
    "            Co-occurence matrix of word counts. \n",
    "            The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
    "        word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
    "\"\"\"\n",
    "\n",
    "def compute_co_occurrence_matrix(corpus, window_size):\n",
    "\n",
    "    \n",
    "    # call the distinct words function to use unique words\n",
    "    corpus_words_dist, corpus_words_dist_cnt = distinct_words(corpus)\n",
    "    \n",
    "    M = None       # set to none at start of function\n",
    "    word2Idx = {}  # set to blank at start of function\n",
    "\n",
    "    # Create a matrix based on size of corpus after runing distinct_words function\n",
    "    M = np.zeros((corpus_words_dist_cnt, corpus_words_dist_cnt))  # create n by n matrix\n",
    "    \n",
    "    # Creates an word:index dictionary of entire unique word corpus\n",
    "    word2Ind = dict(zip(corpus_words_dist, range(corpus_words_dist_cnt)))\n",
    "\n",
    "    # Loop through each document (list of words) in corpus\n",
    "    for doc in corpus:\n",
    "        \n",
    "        # cur_idx will be the index number of each word within that document\n",
    "        # -used to sysematically go through each word (0 to len(doc)) and find words\n",
    "        # -that are window_size positions before and after that word\n",
    "        cur_idx = 0         # resets at 0 at start of each document\n",
    "        doc_len = len(doc)  # word count of each document\n",
    "        \n",
    "        ## while index is between zero and document length\n",
    "        while cur_idx < doc_len:\n",
    "            # far left and far right index numbers (based on cur_idx & window_size)\n",
    "            l_bound = max(cur_idx - window_size, 0)   # max excludes negative indices\n",
    "            r_bound = min(cur_idx + window_size + 1, doc_len)   # min stops at doc_len\n",
    "            \n",
    "            # all words for this iterations window index numbers (l_bound to r_bound)\n",
    "            window_words = doc[l_bound:cur_idx] + doc[(cur_idx + 1):r_bound]\n",
    "            \n",
    "            # get the word associated with the cur_idx\n",
    "            center_word = doc[cur_idx]\n",
    "            \n",
    "            # using that center_word, get it's index number within the entire corpus\n",
    "            #center_idx = word2Idx[center_word]\n",
    "\n",
    "            # Now that we have all the words in a specific window, count the number\n",
    "            # of times each word in the word window appears near the center word in\n",
    "            # the full corpus (within the window size)\n",
    "            for window_word in window_words:\n",
    "                # get full corpus dict index for the window word\n",
    "                window_idx = word2Ind[window_word]\n",
    "                # add 1 in matrix M for each window match\n",
    "                M[window_idx, word2Ind[center_word]] += 1\n",
    "                \n",
    "            cur_idx += 1\n",
    "            \n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Matrix Dimensionality\n",
    "\n",
    "- The resulting matrix from compute_co_occurrence_matrix is a large sparse matrix of shape:\n",
    "    - distinct words rows x distinct words columns\n",
    "- Singular Value Decomposition (SVD) is a generalized PCA to select top k principal components thus reducing the dimensionality and improving processing time while keeping semantic relationships between words\n",
    "    - SVD is computationally expensive so trucated SVD can provide k vector components if k is expected to be small\n",
    "        - https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "        - All of numpy, scipy, and scikit-learn (sklearn) provide some implementation of SVD, but\n",
    "        - Only scipy and sklearn provide an implementation of Truncated SVD, and \n",
    "        - Only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)\n",
    "    to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:\n",
    "        - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "\n",
    "    Params:\n",
    "        M (numpy matrix of shape (number of corpus words, number of corpus words)): co-occurence matrix of word counts\n",
    "        k (int): embedding size of each word after dimension reduction\n",
    "    Return:\n",
    "        M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.\n",
    "                In terms of the SVD from math class, this actually returns U * S\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def reduce_to_k_dim(M, k):\n",
    "\n",
    "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
    "    seed = 3232  # set seed\n",
    "    # create new blank M_reduced (reset each time function is run)\n",
    "    M_reduced = None\n",
    "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
    "\n",
    "    tsvd = TruncatedSVD(n_components=k,\n",
    "                        n_iter=n_iters,\n",
    "                        random_state=seed)\n",
    "    M_reduced = tsvd.fit_transform(M)\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return M_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot M_reduced Word Embeddings\n",
    "\n",
    "- 2D vectors plotted using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
    "        NOTE: do not plot all the words listed in M_reduced / word2Ind.\n",
    "        Include a label next to each point.\n",
    "        \n",
    "        Params:\n",
    "            M_reduced (numpy matrix of shape (number of unique words in the corpus , k)): matrix of k-dimensioal word embeddings\n",
    "            word2Ind (dict): dictionary that maps word to indices for matrix M\n",
    "            words (list of strings): words whose embeddings we want to visualize\n",
    "\"\"\"\n",
    "\n",
    "def plot_embeddings(M_reduced, word2Ind, words):\n",
    "    x_coords = M_reduced[:, 0]\n",
    "    y_coords = M_reduced[:, 1]\n",
    "    \n",
    "    for word in words:\n",
    "        idx = word2Ind[word]\n",
    "        M_reduced_word = M_reduced[idx]\n",
    "        x = M_reduced_word[0]\n",
    "        y = M_reduced_word[1]\n",
    "        \n",
    "        plt.scatter(x, y, marker='x', color='red')\n",
    "        plt.text(x, y, word, fontsize=8)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Functions with Co-occurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 8185 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "reuters_corpus = read_corpus()\n",
    "my_corpus = reuters_corpus\n",
    "\n",
    "M_co_occurrence, word2Ind_co_occrrence = compute_co_occurrence_matrix(my_corpus, window_size = 4)\n",
    "M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k = 2)\n",
    "\n",
    "# Rescale rows to make them each of unit-length\n",
    "M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis = 1)\n",
    "M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # uses numpy array broadcasting\n",
    "\n",
    "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry',\n",
    "         'kuwait', 'oil', 'output', 'petroleum', 'venezuela']\n",
    "plot_embeddings(M_normalized, word2Ind_co_occrrence, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the output above: some clusters seem to align while others are where we would expect them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction-based word vectors: word2vec\n",
    "- using Word2Vec skip-gram model\n",
    "    - develop vector representation of a center word such that it predicts nearby words\n",
    "    - see paper: https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec():\n",
    "    \n",
    "    import gensim.downloader as api\n",
    "    \n",
    "    wv_from_bin = api.load('word2vec-google-news-300')\n",
    "    vocab = list(wv_from_bin.vocab.keys())\n",
    "    \n",
    "    print('Loaded vocab size %i' % len(vocab))\n",
    "    return wv_from_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 6.7% 110.9/1662.8MB downloaded"
     ]
    }
   ],
   "source": [
    "wv_from_bin = load_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
