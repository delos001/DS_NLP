{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.decomposition import  LatentDirichletAllocation\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "raw_data=pd.read_csv(\"C:/Users/AyankoyaKayode/OneDrive - PRA Health Sciences/PRA/NLP/citeline_rare_disease.csv\", header=1,\n",
    "                     names = ['INCLD_CRTERIA','EXCLD_CRTERIA'], encoding=\"ISO-8859-1\")\n",
    "\n",
    "whole_data=pd.read_csv(\"C:/Users/AyankoyaKayode/OneDrive - PRA Health Sciences/PRA/NLP/citeline_rare_disease.csv\", header=0,\n",
    "                     encoding=\"ISO-8859-1\")\n",
    "\n",
    "\n",
    "whole_data_non=whole_data.dropna()\n",
    "\n",
    "incld_list=whole_data_non['INCLD_CRTERIA'].tolist()\n",
    "\n",
    "excld_list=whole_data_non['EXCLD_CRTERIA'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = len(raw_data)\n",
    "n_features = round(n_samples/6)\n",
    "n_topics = len(whole_data.groupby('PRA_STUDY_ID')['PRA_STUDY_ID'].count())\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    list_term_temp=[]\n",
    "    #list_idx=[]\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        #list_term_temp=[]\n",
    "        #print(\"Topic #%d:\" % topic_idx)\n",
    "        #list_idx.append(topic_idx)\n",
    "        #print(\" \".join([feature_names[i]\n",
    "        #                for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        for i in topic.argsort()[:-n_top_words -1:-1]:\n",
    "            list_term_temp.append(feature_names[i])\n",
    "            \n",
    "        #list_term.append(list_term_temp)\n",
    "    \n",
    "    #dic=pd.DataFrame({'topic_index':list_idx, 'terms':list_term})\n",
    "    #print()\n",
    "    return list_term_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples_incld = incld_list\n",
    "data_samples_excld = excld_list\n",
    "\n",
    "\n",
    "tf_vectorizer_incld = CountVectorizer(max_df=0.6, min_df=4, ngram_range=(2,2),\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "\n",
    "tf_vectorizer_excld = CountVectorizer(max_df=0.6, min_df=4, ngram_range=(2,2),\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "\n",
    "tf_incld = tf_vectorizer_incld.fit_transform(data_samples_incld)\n",
    "\n",
    "tf_excld = tf_vectorizer_excld.fit_transform(data_samples_excld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "#vect=CountVectorizer(ngram_range=(1,1),stop_words='english')\n",
    "#fin=vect.fit_transform(financedoc)\n",
    "######pd.DataFrame(tf_incld.toarray(),columns=tf_vectorizer_excld.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2081 and n_features=347...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AyankoyaKayode\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\AyankoyaKayode\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda_incld = lda.fit(tf_incld)\n",
    "lda_excld = lda.fit(tf_excld)\n",
    "\n",
    "\n",
    "tf_feature_names_incld = tf_vectorizer_incld.get_feature_names()\n",
    "incld_terms = print_top_words(lda_incld, tf_feature_names_incld, n_top_words)\n",
    "\n",
    "tf_feature_names_incld = tf_vectorizer_excld.get_feature_names()\n",
    "excld_terms = print_top_words(lda_excld, tf_feature_names_incld, n_top_words)\n",
    "\n",
    "\n",
    "incld_terms_list = list(dict(Counter(incld_terms).most_common(100)))\n",
    "excld_terms_list = list(dict(Counter(excld_terms).most_common(100)))\n",
    "\n",
    "unique_incld = list(set(incld_terms_list) - set(excld_terms_list))\n",
    "unique_excld = list(set(excld_terms_list) - set(incld_terms_list)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dict(Counter(excld_terms))\n",
    "#dict(Counter(incld_terms))\n",
    "\n",
    "sorting=np.argsort(lda.components_)[:,::-1]\n",
    "features=np.array(tf_vectorizer_excld.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       \n",
      "--------      \n",
      "situ cervix   \n",
      "qt interval   \n",
      "investigator jeopardize\n",
      "acute chronic \n",
      "highly effective\n",
      "female subjects\n",
      "interfere evaluation\n",
      "inflammatory bowel\n",
      "defined investigator\n",
      "clinically relevant\n",
      "14 days       \n",
      "congestive heart\n",
      "12 months     \n",
      "study months  \n",
      "pregnant breast\n",
      "\n",
      "\n",
      "topic 1       \n",
      "--------      \n",
      "cns metastases\n",
      "breast feeding\n",
      "known suspected\n",
      "hepatic decompensation\n",
      "history chronic\n",
      "inflammatory bowel\n",
      "suicide attempt\n",
      "corticosteroid treatment\n",
      "female subjects\n",
      "liver disease \n",
      "participation investigational\n",
      "subject history\n",
      "laboratory results\n",
      "defined investigator\n",
      "laboratory abnormality\n",
      "\n",
      "\n",
      "topic 2       \n",
      "--------      \n",
      "prior randomization\n",
      "prior treatment\n",
      "months prior  \n",
      "blood pressure\n",
      "uncontrolled hypertension\n",
      "congestive heart\n",
      "years prior   \n",
      "investigational agent\n",
      "medications known\n",
      "basal cell    \n",
      "immunodeficiency virus\n",
      "condition opinion\n",
      "cell skin     \n",
      "active infection\n",
      "gastrointestinal disorder\n",
      "\n",
      "\n",
      "topic 3       \n",
      "--------      \n",
      "current diagnosis\n",
      "28 days       \n",
      "prior baseline\n",
      "subject previously\n",
      "days prior    \n",
      "exclusion criteria\n",
      "currently receiving\n",
      "study subject \n",
      "pregnant breast\n",
      "hepatitis infection\n",
      "currently taking\n",
      "breast feeding\n",
      "prednisone equivalent\n",
      "90 days       \n",
      "subject currently\n",
      "\n",
      "\n",
      "topic 4       \n",
      "--------      \n",
      "uncontrolled hypertension\n",
      "substance abuse\n",
      "squamous cell \n",
      "current diagnosis\n",
      "transient ischemic\n",
      "current treatment\n",
      "significant cardiovascular\n",
      "clinical trial\n",
      "screening visit\n",
      "absolute neutrophil\n",
      "24 hours      \n",
      "exclusion criteria\n",
      "immunodeficiency virus\n",
      "subject pregnant\n",
      "peripheral neuropathy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mglearn\n",
    "dd1 = mglearn.tools.print_topics(topics=range(5), feature_names=features,sorting=sorting, topics_per_chunk=1, n_words=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6089c677cc13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdd1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
